{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Tesina di Open Data Management 2023/2024**\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"OpenData.jpg\" width=\"1200\" height=\"auto\">\n",
    "\n",
    "### <center> _Casano Giovanni, Castronovo Emanuele_\n",
    "##### <center> 21 Giugno \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Indice__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [`1. - Traccia`](#1-traccia)\n",
    "### [`2. - Selezione dei dataset`](#2-selezione-dei-dataset)\n",
    "##### &emsp;&emsp; [`2.1 - Raccolta`](#21-raccolta)\n",
    "##### &emsp;&emsp; [`2.2 - Licenze`](#22-licenze)\n",
    "### [`3. - Elaborazione dei dataset`](#3-elaborazione-dei-dataset)\n",
    "##### &emsp;&emsp; [`3.1 - Pulizia e selezione dei dati rilevanti`](#31-pulizia-e-selezione-dei-dati-rilevanti)\n",
    "##### &emsp;&emsp; [`3.2 - Arricchimento`](#32-arricchimento)\n",
    "### [`4. - Trasformazione dei dataset a 5 stelle`](#4-trasformazione-dei-dataset-a-5-stelle)\n",
    "##### &emsp;&emsp; [`4.1 - Ontologia`](#41-ontologia)\n",
    "##### &emsp;&emsp; [`4.2 - Passaggio a 5 stelle`](#42-passaggio-a-5-stelle)\n",
    "### [`5. - Data visualization`](#5-data-visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __`1 Traccia`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per lo sviluppo del progetto, utilizzeremo strumenti come Python, Open Refine, Protege, SQL, SPARQL, GraphDB, etc... seguendo i seguenti passi fondamentali:\n",
    "\n",
    "- **Selezione dati;**\n",
    "- **Elaborazione dati (data cleaning, definizione di una struttura omogenea);**\n",
    "- **Open Linked Data (creazione di uno strato semantico, ontologie, interlinking).**\n",
    "\n",
    "L'obiettivo del progetto è analizzare i dati sui veicoli immatricolati nella regione Sicilia fino all'anno 2020, con un focus particolare sulla categoria EURO a cui appartengono, e i dati delle misurazioni ambientali di varie stazioni Siciliane relative alla qualità dell'aria e alla temperatura. Il nostro scopo è sviluppare una base di conoscenza mettendo in relazione il numero di veicoli di una determinata categoria EURO, circolanti in varie città siciliane, con la qualità dell'aria (in termini di agenti inquinanti emessi) e la temperatura registrata in quelle stesse città.\n",
    "\n",
    "In particolare, intendiamo analizzare e verificare l'impatto dei veicoli con una categoria EURO più bassa, che quindi inquinano di più, sulla qualità complessiva dell'aria e sulla temperatura cittadina. Vogliamo dimostrare come l'adozione di veicoli con una categoria EURO più alta, e quindi meno inquinanti, possa contribuire significativamente a migliorare la qualità ambientale e ridurre l'inquinamento atmosferico. Questa analisi mira a evidenziare i benefici ambientali derivanti dall'uso di veicoli più ecologici.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __`2 Selezione dei dataset`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### __`2.1 Raccolta`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selezione dei dataset\n",
    "\n",
    "### Raccolta\n",
    "\n",
    "Per il nostro progetto, abbiamo selezionato diversi dataset, tutti nel formato csv, che forniscono una visione completa e dettagliata dei veicoli immatricolati, della qualità dell'aria e della temperatura per diverse città della regione Sicilia per l'anno 2020. I dataset utilizzati includono:\n",
    "\n",
    "- **Parco Circolante della regione Sicilia (2020)**: Questo dataset fornisce informazioni dettagliate sui veicoli immatricolati nella regione, inclusa la categoria EURO a cui appartengono.\n",
    "  \n",
    "- **Anagrafica dei sensori meteo**: Gestita da SIAS, questa anagrafica include informazioni dettagliate sui sensori utilizzati per monitorare le condizioni meteorologiche, con un focus specifico sulle rilevazioni di temperatura.\n",
    "\n",
    "- **Anagrafica degli inquinanti e delle stazioni di rilevamento**: Fornita da ARPA, questo dataset comprende informazioni sui tipi di inquinanti monitorati e le stazioni di rilevamento utilizzate per il monitoraggio della qualità dell'aria.\n",
    "\n",
    "- **Rilevazioni della qualità dell'aria (2020)**: Questo dataset contiene dati sulle rilevazioni della qualità dell'aria effettuate nel 2020, con particolare attenzione agli agenti inquinanti emessi dai veicoli.\n",
    "\n",
    "- **Rilevazioni della temperatura (2020)**: Comprende i dati sulle rilevazioni della temperatura per l'anno 2020.\n",
    "\n",
    "In particolare si è deciso di concentrare la nostra analisi sui mesi di Aprile, Luglio, Ottobre e Dicembre per avere una visione più completa possibile delle rilevazioni ed esaminare la situazione ambientale nelle varie stagioni del 2020 nelle città della Sicilia prese in considerazione.\n",
    "***\n",
    "Seguono i link da cui sono stati reperiti i dataset.\n",
    "\n",
    "`Parco Circolante:` <br>\n",
    "_https://dati.mit.gov.it/catalog/dataset/dataset-parco-circolante-dei-veicoli/resource/241d337d-5469-4f57-a002-fe4a23944b41_\n",
    "\n",
    "`Anagrafica Temperatura:` <br>\n",
    "_https://dati.regione.sicilia.it/catalogo/8efbe160-01da-470c-8834-47c9ada4975c_\n",
    "\n",
    "`Anagrafica Inquinanti e Qualità dell'Aria:` <br>\n",
    "_https://dati.regione.sicilia.it/catalogo/arpa-qualita-aria-anagrafica_\n",
    "\n",
    "`Rilevazione temperatura:` <br>\n",
    "_https://dati.regione.sicilia.it/catalogo/fed5b98f-31a5-4510-8541-f137e419c5ef_\n",
    "\n",
    "`Rilevazioni inquinanti qualità dell'aria:` <br>\n",
    "_https://dati.regione.sicilia.it/catalogo/arpa-qualita-aria-2020_\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`2.2 Licenze`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parco Circolante:` Creative Commons BY, versione 4.0\n",
    "\n",
    "`Anagrafica Temperatura:` Creative Commons BY, versione 4.0\n",
    "\n",
    "`Anagrafica Inquinanti e Qualità dell'Aria:` Creative Commons BY, versione 4.0\n",
    "\n",
    "`Rilevazione temperatura:` Creative Commons BY, versione 4.0\n",
    "\n",
    "`Rilevazioni inquinanti qualità dell'aria:` Creative Commons BY, versione 4.0\n",
    "\n",
    "<u>Il presente notebook, compreso di tutto il necessario per la sua corretta esecuzione, è distribuito con licenza CC-BY 4.0.</u>\n",
    "\n",
    "Visto che le licenze dei dataset e del notebook sono tutte CC-BY 4.0 sono ovviamente compatibili tra di loro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __`3 Elaborazione dei dataset`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione, tutti i dataset prodotti sono classificati come dati a 3 stelle e vengono esportati in formato Parquet. Parquet è un formato di file orientato alle colonne, ottimizzato per gestire e archiviare grandi volumi di dati. Grazie alla sua efficienza in termini di spazio e velocità di lettura, è particolarmente adatto per i big data e l'analisi dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`3.1 Data Cleaning`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`3.1.2 Verifica della correttezza dei dati`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa fase è stata eseguita durante la fase della raccolta dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`3.1.3 Pulizia dei dati`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa fase prevede due sottofasi, una prima eseguita con Open Refine e una seconda in Python ed SQL.  \n",
    "La scelta di dividere questa fase in due sottofasi è puramente per motivi pratici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`3.1.3.1 Open Refine`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Parco Circolante Sicilia`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le operazioni di pulizia effettuate sono state:\n",
    "\n",
    "- **Ridenominazione della colonna “Anno immatricolazione”**: vista la sua manipolazione frequente, nelle fasi successive, in SQL, la ridenominazione in “AnnoImmatricolazione” ha prevenuto eventuali errori sintattici.\n",
    "- **Eliminazione dei veicoli elettrici**: poiché questi non inquinano, sono stati esclusi dall'analisi.\n",
    "- **Verifica e pulizia delle colonne**: eliminazione di tutte le righe che presentano valori nulli per le colonne “EURO”, “Marca”, “Città”, “AnnoImmatricolazione”, “Carburante”. Non è stata scelto il riempimento delle celle con valori standard poiché queste informazioni sono rilevanti per l'analisi che è stata preposta. \n",
    "- **Gestione delle celle vuote nella colonna “Cavalli”**: a differenza di alcune colonne, menzionate sopra, quella relativa ai cavalli non è rilevante per l'analisi. Tuttavia, riscontrando il basso numero di righe con questa cella vuota, si è deciso di riempire le celle con un valore di default pari a 1 e preservare, anziché perdere, questa informazione nel grafo delle conoscenze.\n",
    "- **Trasformazione del formato della data**: il formato della data è stato convertito da “DD/MM/YYYY” a “YYYY-MM-DD” utilizzando l'espressione regolare `value.split(\"/\").reverse().join(\"-\")` in linguaggio “GREL”. L'utilizzo del formato standard “YYYY-MM-DD” permette una corretta manipolazione dei dati in Python, SQL e SPARQL.\n",
    "- **Modifica del valore di “EURO”**: per le auto di marca Ferrari, inizialmente il valore era “N” che è stato corretto in EURO 6 visto l'anno di immatricolazione piuttosto recente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per l'anagrafica dei sensori meteo, non è stata necessaria alcuna operazione di data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Rilevazione Temperatura`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per le rilevazioni della temperatura nei mesi di aprile, luglio e ottobre, abbiamo effettuato le seguenti operazioni:\n",
    "\n",
    "- **Rimozione della colonna ID_PAR**: Questa colonna è stata rimossa in quanto irrilevante per la nostra analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Dataset Qualità dell'Aria`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per i dataset relativi alla qualità dell'aria, sono state eseguite le seguenti operazioni:\n",
    "\n",
    "- **Rimozione delle colonne “periodo_media” e “misura_anno”**: Queste colonne contenevano informazioni futili per la nostra analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Datasets Qualità dell'Aria - Anagrafica Stazioni`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inserimento delle coordinate mancanti**: Le stazioni “Augusta Villa Augusta” e “Gela Pontile” sono state completate con le coordinate mancanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Datasets Qualità dell'Aria - Anagrafica Inquinanti`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rimozione di righe relative agli agenti inquinanti “NOX”, “H2S3”, “O3”**: Questi agenti non sono stati considerati per la nostra indagine poiché non emessi dettagliatamente dai motori endotermici\n",
    "- **Ordinamento delle righe**: Le righe sono state ordinate in base all'ID Inquinante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`3.1.3.2 Python`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fase di data cleaning viene eseguita integrando SQL in Python grazie alla libreria `duckdb`. La scelta di utilizzare tale libreria è dovuta non solo alla semplicità di scrittura del codice grazie ad SQL ma anche per l'ottimizzazione nel leggere ed esportare file CSV e/o parquet di grandi dimensioni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import re\n",
    "from rdflib import Graph, Literal, URIRef, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sono state importate anche librerie che servono per le fasi successive dell'analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Apertura connessione con duckdb per tutte le operazioni di manipolazione\n",
    "# dei dataset\n",
    "# =============================================================================\n",
    "\n",
    "database = duckdb.connect(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Creazione parquet per anagrafica inquinanti`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli inquinanti vengono ordinati in modo crescente per il loro ID numerico per una migliore leggibilità dei risultati e una ricerca più efficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CSV\n",
    "# =============================================================================\n",
    "\n",
    "# database.execute(f\"\"\"\n",
    "#             COPY \n",
    "#                 (\n",
    "#                     SELECT *\n",
    "#                     FROM read_csv_auto('csvOpenRefine/arpa-qualita-aria-anagrafica-inquinanti_csv.csv', header=True, sep=',')\n",
    "#                     ORDER BY (inquinante_id) ASC\n",
    "#                 )\n",
    "#             TO\n",
    "#                 'csv/arpa_qualita_aria_anagrafica_inquinanti.csv' (FORMAT CSV, HEADER)\n",
    "#         \"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# Parquet\n",
    "# =============================================================================\n",
    "database.execute(f\"\"\"\n",
    "            COPY \n",
    "                (\n",
    "                    SELECT *\n",
    "                    FROM read_csv_auto('csvOpenRefine/arpa-qualita-aria-anagrafica-inquinanti_csv.csv', header=True, sep=',')\n",
    "                    ORDER BY (inquinante_id) ASC\n",
    "                )\n",
    "            TO\n",
    "                'parquet/arpa_qualita_aria_anagrafica_inquinanti.parquet' (FORMAT PARQUET)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Filtraggio dei valori per città`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nei dataset dell'anagrafica delle stazioni dell'aria, della temperatura e del parco circolante dei veicoli, sono presenti differenti città. Volendo analizzare l'inquinamento nelle citta siciliane, è necessario che per queste città vi sia __almeno__ una stazione dell'aria, della temperatura ed un veicolo circolante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Calcolo delle città rilevanti\n",
    "# =============================================================================\n",
    "pathAnagraficaSensoriMeteo = \"csvOpenRefine/elenco-sensori-meteo_csv_rsd.csv\"\n",
    "pathAnagraficaStazioniAria = \"csvOpenRefine/arpa-qualita-aria-anagrafica-stazioni_csv.csv\"\n",
    "pathParcoCircolante = \"csvOpenRefine/Circolante-Sicilia.csv\"\n",
    "\n",
    "database.execute(f\"\"\"\n",
    "                CREATE OR REPLACE VIEW cittaSelezionate AS \n",
    "                SELECT DISTINCT file2.stazione_id as stazioneId, file1.ID_STAZ as sensoreId, file2.citta \n",
    "                FROM read_csv_auto('{pathAnagraficaSensoriMeteo}', header=True, sep=',') as file1\n",
    "                JOIN read_csv_auto('{pathAnagraficaStazioniAria}', header=True, sep=',') as file2\n",
    "                ON (lower(file1.COMUNE_NOME) = lower(file2.citta)) AND lower(file2.citta) IN (SELECT DISTINCT lower(Città) FROM read_csv_auto('{pathParcoCircolante}', header=True, sep=','))\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutte le stazioni, sia che misurano gli inquinanti o la temperatura, ed i veicoli che non si trovano nelle città determinate, vengono rimossi in quanto inutili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Eliminazione delle anagrafiche delle stazione dell'aria e dei sensori meteo \n",
    "# che non rientrano nella lista determinata\n",
    "# =============================================================================\n",
    "\n",
    "# Parquet\n",
    "database.execute(f\"\"\"\n",
    "                COPY \n",
    "                    (\n",
    "                        SELECT *\n",
    "                        FROM read_csv_auto('{pathAnagraficaSensoriMeteo}', header=True, sep=',')\n",
    "                        WHERE ID_STAZ IN (SELECT DISTINCT sensoreId FROM cittaSelezionate)\n",
    "                        ORDER BY (ID_STAZ) ASC\n",
    "                    )\n",
    "                TO\n",
    "                    'parquet/elenco_sensori_meteo.parquet' (FORMAT PARQUET)\n",
    "            \"\"\")\n",
    "database.execute(f\"\"\"\n",
    "                COPY \n",
    "                    (\n",
    "                        SELECT *\n",
    "                        FROM read_csv_auto('{pathAnagraficaStazioniAria}', header=True, sep=',')\n",
    "                        WHERE stazione_id IN (SELECT DISTINCT stazioneId FROM cittaSelezionate)\n",
    "                        ORDER BY (stazione_id) ASC\n",
    "                    )\n",
    "                TO\n",
    "                    'parquet/arpa_qualita_aria_anagrafica_stazioni.parquet' (FORMAT PARQUET)\n",
    "            \"\"\")\n",
    "\n",
    "# CSV\n",
    "# database.execute(f\"\"\"\n",
    "#                 COPY \n",
    "#                     (SELECT *\n",
    "#                     FROM read_csv_auto('{pathAnagraficaSensoriMeteo}', header=True, sep=',')\n",
    "#                     WHERE ID_STAZ IN (SELECT DISTINCT sensoreId FROM cittaSelezionate)\n",
    "#                     ORDER BY (ID_STAZ) ASC)\n",
    "#                 TO\n",
    "#                     'csv/elenco_sensori_meteo.csv' (FORMAT CSV, HEADER)\n",
    "#             \"\"\")\n",
    "# database.execute(f\"\"\"\n",
    "#                 COPY \n",
    "#                     (SELECT *\n",
    "#                     FROM read_csv_auto('{pathAnagraficaStazioniAria}', header=True, sep=',')\n",
    "#                     WHERE stazione_id IN (SELECT DISTINCT stazioneId FROM cittaSelezionate)\n",
    "#                     ORDER BY (stazione_id) ASC)\n",
    "#                 TO\n",
    "#                     'csv/arpa_qualita_aria_anagrafica_stazioni.csv' (FORMAT CSV, HEADER)\n",
    "#             \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Filtraggio parco circolante\n",
    "# =============================================================================\n",
    "\n",
    "# CSV\n",
    "# database.execute(f\"\"\"\n",
    "#             COPY \n",
    "#                 (\n",
    "#                     SELECT *\n",
    "#                     FROM read_csv_auto('csvOpenRefine/Circolante-Sicilia.csv', header=True, sep=',')\n",
    "#                     WHERE lower(Città) IN (SELECT DISTINCT lower(citta) FROM cittaSelezionate)\n",
    "#                     ORDER BY AnnoImmatricolazione ASC\n",
    "#                 )\n",
    "#             TO\n",
    "#                 'csv/Circolante_Sicilia.csv' (FORMAT CSV, HEADER)\n",
    "#         \"\"\")\n",
    "\n",
    "# Parquet\n",
    "database.execute(f\"\"\"\n",
    "            COPY \n",
    "                (\n",
    "                    SELECT *\n",
    "                    FROM read_csv_auto('csvOpenRefine/Circolante-Sicilia.csv', header=True, sep=',')\n",
    "                    WHERE lower(Città) IN (SELECT DISTINCT lower(citta) FROM cittaSelezionate)\n",
    "                    ORDER BY AnnoImmatricolazione ASC\n",
    "                )\n",
    "            TO\n",
    "                'parquet/Circolante_Sicilia.parquet' (FORMAT PARQUET)\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ulteriori Operazioni con Python\n",
    "\n",
    "- **Compressione giornaliera delle rilevazioni**: Le rilevazioni dei vari dataset sulla qualità dell'aria sono state compresse giornalmente, vista la mancanza di rilevazioni orarie per alcuni di essi.\n",
    "- **Creazione dei file Parquet per le rilevazioni**: Questa operazione migliora l'efficienza nella visualizzazione con DuckDB in Python e con altre librerie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __`Data Compression`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la fase di data cleaning con Open Refine è stato osservato che per gli inquinanti “5” e “6001”, le rilevazioni non erano con cadenza oraria, come per gli altri inquinanti, ma giornaliera. Volendo eseguire un'analisi per i mesi di aprile, luglio, ottobre e dicembre, è stato conveniente valutare il valore misurato degli altri inquinanti con cadenza giornaliera anziché oraria. Avendo a disposizione misure con cadenza oraria, il valore assegnato al generico giorno è stato la media di tutti i valori misurati nell'arco delle 24h. La possibile assenza di alcune misurazione in certe fasce orarie non ha un impatto significativo per la validità dei dati in quanto la media è un filtro a passa basso. Inoltre, sono state prese in considerazione soltanto le rilevazione nei mesi di aprile, luglio, ottobre e dicembre, e le stazioni le cui città rientrano in quelle selezionate precedentemente.  \n",
    "La compressione eseguita è di tipo `lossy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Compressione per le stazioni che rilevano la quantità degli inquinanti\n",
    "# nell'aria\n",
    "# =============================================================================\n",
    "\n",
    "def compressioneRilevazioniGiornaliereAria(path,database):\n",
    "    nomeFile = re.sub(\"-\",\"_\",path[14:len(path)-8])\n",
    "    \n",
    "    # CSV\n",
    "    # database.execute(f\"\"\"\n",
    "    #                 COPY \n",
    "    #                 (\n",
    "    #                     SELECT stazione_id AS stazioneId, inquinante_id AS inquinanteId, AVG(misura_valore) as valoreMisurato, CAST(misura_dataora AS DATE) as data \n",
    "    #                     FROM read_csv_auto('{path}', header=True, sep=',')\n",
    "    #                     WHERE stazione_id IN (SELECT DISTINCT stazioneId FROM cittaSelezionate) AND EXTRACT(MONTH FROM CAST(misura_dataora AS DATE)) IN (4,7,10,12)\n",
    "    #                     GROUP BY (stazioneId,inquinanteId,data)\n",
    "    #                     ORDER BY (stazioneId,data) ASC\n",
    "    #                 )\n",
    "    #                 TO\n",
    "    #                     'csv/{nomeFile}.csv' (FORMAT CSV, HEADER)\n",
    "    #             \"\"\")\n",
    "    \n",
    "    # Parquet\n",
    "    database.execute(f\"\"\"\n",
    "                    COPY \n",
    "                    (\n",
    "                        SELECT stazione_id AS stazioneId, inquinante_id AS inquinanteId, AVG(misura_valore) as valoreMisurato, CAST(misura_dataora AS DATE) as data \n",
    "                        FROM read_csv_auto('{path}', header=True, sep=',')\n",
    "                        WHERE stazione_id IN (SELECT DISTINCT stazioneId FROM cittaSelezionate) AND EXTRACT(MONTH FROM CAST(misura_dataora AS DATE)) IN (4,7,10,12)\n",
    "                        GROUP BY (stazioneId,inquinanteId,data)\n",
    "                        ORDER BY (stazioneId,data) ASC\n",
    "                    )\n",
    "                    TO\n",
    "                        'parquet/{nomeFile}.parquet' (FORMAT PARQUET)\n",
    "                \"\"\")\n",
    "    \n",
    "percorsi = [\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-1_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-5_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-8_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-10_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-20_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-32_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-38_csv.csv\",\n",
    "    \"csvOpenRefine/arpa-qualita-aria-2020-6001_csv.csv\"\n",
    "]\n",
    "for path in percorsi:\n",
    "    compressioneRilevazioniGiornaliereAria(path,database)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data compression in temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Compressione per le stazioni che rilevano la temperatura\n",
    "# =============================================================================\n",
    "\n",
    "def compressioneRilevazioniGiornaliereTemperature(path,database):\n",
    "    nomeFile = re.sub(\"-\",\"_\",path[14:len(path)-4])\n",
    "    \n",
    "    # CSV\n",
    "    # database.execute(f\"\"\"\n",
    "    #                 COPY \n",
    "    #                 (\n",
    "    #                     SELECT ID_STAZ AS stazioneId, AVG(VALORE) as valoreMisurato, CAST(DATARIL AS DATE) as data \n",
    "    #                     FROM read_csv_auto('{path}', header=True, sep=',')\n",
    "    #                     WHERE ID_STAZ IN (SELECT DISTINCT sensoreId FROM cittaSelezionate)\n",
    "    #                     GROUP BY (stazioneId,data)\n",
    "    #                     ORDER BY (stazioneId,data) ASC\n",
    "    #                 )\n",
    "    #                 TO\n",
    "    #                     'csv/{nomeFile}.csv' (FORMAT CSV, HEADER)\n",
    "    #             \"\"\")\n",
    "    \n",
    "    # Parquet\n",
    "    database.execute(f\"\"\"\n",
    "                    COPY \n",
    "                    (\n",
    "                        SELECT ID_STAZ AS stazioneId, AVG(VALORE) as valoreMisurato, CAST(DATARIL AS DATE) as data \n",
    "                        FROM read_csv_auto('{path}', header=True, sep=',')\n",
    "                        WHERE ID_STAZ IN (SELECT DISTINCT sensoreId FROM cittaSelezionate)\n",
    "                        GROUP BY (stazioneId,data)\n",
    "                        ORDER BY (stazioneId,data) ASC\n",
    "                    )\n",
    "                    TO\n",
    "                        'parquet/{nomeFile}.parquet' (FORMAT PARQUET)\n",
    "                \"\"\")\n",
    "percorsi = [\n",
    "    \"csvOpenRefine/sias-temperatura-aria-a-2-metri_2020_4.csv\",\n",
    "    \"csvOpenRefine/sias-temperatura-aria-a-2-metri_2020_7.csv\",\n",
    "    \"csvOpenRefine/sias-temperatura-aria-a-2-metri_2020_10.csv\",\n",
    "    \"csvOpenRefine/sias-temperatura-aria-a-2-metri_2020_12.csv\",\n",
    "]\n",
    "for path in percorsi:\n",
    "    compressioneRilevazioniGiornaliereTemperature(path,database)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusioni della Prima Fase di Data Cleaning\n",
    "\n",
    "La prima fase del data cleaning ha comportato una significativa riduzione del numero di righe e della dimensione complessiva dei dataset, migliorando la qualità e la gestibilità dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`3.2 Arricchimento`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa fase è cruciale per l'interlinking tra le città presenti nella nostra base di conoscenza e le città presenti sul __vocabolario controllato dei comuni d'italia__, reperibile presso `https://w3id.org/italia/controlled-vocabulary/territorial-classifications/cities/`, facente parte del catologo nazionale dei dati `https://schema.gov.it/`.   \n",
    "Le informazioni più rilevanti, ai fini dell'analisi, sono:\n",
    "- nome della città\n",
    "- nome della provincia\n",
    "- codice istat\n",
    "- data di inizio\n",
    "- data di fine  \n",
    "\n",
    "Le città, nel corso del tempo, possono passare da una provincia all'altra. La diretta conseguenza di questo aspetto è la possibile comparsa più volte di una città nel vocabolario citato. Il periodo in cui una città fa parte di una provincia va dalla '_data di inizio_' fino alla '_data di fine_'. Il nostro obiettivo è prendere tutti i comuni la cui __provincia corrente__ faccia parte della regione __Sicilia__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La query __SPARQL__ utilizzata per reperire le informazioni relative ai vari comuni d'italia, la cui provincia fa parte della regione Sicilia, è la seguente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sparql\n",
    "SELECT DISTINCT ?nomeCitta ?nomeProvincia ?codiceIstat ?dataInizio ?dataFine\n",
    "WHERE { \n",
    "    <https://w3id.org/italia/controlled-vocabulary/territorial-classifications/cities> \n",
    "        <http://www.w3.org/2004/02/skos/core#hasTopConcept> ?value .\n",
    "    ?value <http://www.w3.org/2000/01/rdf-schema#label> ?nomeCitta .\n",
    "    ?value <http://www.w3.org/2004/02/skos/core#notation> ?codiceIstat .\n",
    "    ?value <https://w3id.org/italia/onto/CLV/hasSOValidity> ?date .\n",
    "    ?date <https://w3id.org/italia/onto/TI/startTime> ?dataInizio .\n",
    "    ?date <https://w3id.org/italia/onto/TI/endTime> ?dataFine .\n",
    "    ?value <http://www.w3.org/2004/02/skos/core#broader> ?provincia .\n",
    "    ?provincia <http://www.w3.org/2000/01/rdf-schema#label> ?nomeProvincia .\n",
    "    ?provincia <http://www.w3.org/2004/02/skos/core#broader> ?regione .\n",
    "    ?regione <http://www.w3.org/2000/01/rdf-schema#label> ?nomeRegione .\n",
    "    FILTER(LANG(?nomeCitta)=\"it\")\n",
    "    FILTER(LANG(?nomeProvincia)=\"it\")\n",
    "    FILTER(REGEX(?nomeRegione,\"sicilia\",\"i\"))\n",
    "}\n",
    "ORDER BY ?nomeCitta ?nomeProvincia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grazie all'interfaccia __SPARQL__ messa a disposizione `https://schema.gov.it/sparql`, è stato possibile eseguire la query e scaricare il risultato in formato csv (`csvOpenRefine/codice-province-codiceIstat.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creazione del Parquet delle citta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per la creazione del file Parquet delle città sono stati considerati i massimi della data di inizio e fine validità, poichè in questo modo si va a selezionare le città una singola volta e le province corrette e attuali di ogni città."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "# database.execute(\"\"\"\n",
    "#                     COPY (\n",
    "#                         SELECT *\n",
    "#                         FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',') AS file\n",
    "#                         WHERE dataInizio = (\n",
    "#                             SELECT MAX(dataInizio)\n",
    "#                             FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',')\n",
    "#                             WHERE nomeCitta = file.nomeCitta\n",
    "#                         )\n",
    "#                         AND dataFine = (\n",
    "#                             SELECT MAX(dataFine)\n",
    "#                             FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',')\n",
    "#                             WHERE nomeCitta = file.nomeCitta\n",
    "#                         )\n",
    "#                         AND lower(nomeCitta) IN (SELECT DISTINCT lower(citta) FROM cittaSelezionate)\n",
    "#                         ORDER BY nomeCitta\n",
    "#                     )\n",
    "#                     TO 'csv/citta_province_codiceIstat.csv' (FORMAT CSV, HEADER);\n",
    "#             \"\"\")\n",
    "\n",
    "# Parquet\n",
    "database.execute(\"\"\"\n",
    "                    COPY (\n",
    "                        SELECT *\n",
    "                        FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',') AS file\n",
    "                        WHERE dataInizio = (\n",
    "                            SELECT MAX(dataInizio)\n",
    "                            FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',')\n",
    "                            WHERE nomeCitta = file.nomeCitta\n",
    "                        )\n",
    "                        AND dataFine = (\n",
    "                            SELECT MAX(dataFine)\n",
    "                            FROM read_csv_auto('csvOpenRefine/citta-province-codiceIstat.csv', header=True, sep=',')\n",
    "                            WHERE nomeCitta = file.nomeCitta\n",
    "                        )\n",
    "                        AND lower(nomeCitta) IN (SELECT DISTINCT lower(citta) FROM cittaSelezionate)\n",
    "                        ORDER BY nomeCitta\n",
    "                    )\n",
    "                    TO 'parquet/citta_province_codiceIstat.parquet' (FORMAT PARQUET);\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N.B:` l'operazione di filtraggio delle province correnti viene eseguita in SQL. Nonostante potesse essere eseguita in SPARQL con delle query annidate, ci è sembrato meno costoso navigare più volte un file csv di circa 1500 righe anziché l'intero vocabolario controllato dei comuni d'italia. Inoltre, prima della creazione del parquet, vengono selezionati solo i comuni di nostro interesse. Questa operazione, a differenza della precedente, nel nostro caso, può essere eseguita solamente in SQL prima dell'_export_ in parquet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __`4 Trasformazione dei dataset a 5 stelle`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`4.1 Ontologia`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ontologia sviluppata è un'ontologia __`OWL`__ realizzata tramite l'ausilio del software __`Protege`__.\n",
    "Si struttura attorno a sette classi principali: `City`, `MeasureUnit`, `Measurement`, `Polluting`, `Station`, `Temperature`, e `Vehicle`. Queste classi rappresentano elementi fondamentali nel monitoraggio dell'inquinamento e sono interconnesse tramite proprietà che descrivono relazioni e attributi specifici.\n",
    "\n",
    "La classe `City` rappresenta le città monitorate, includendo dettagli come il codice ISTAT, la provincia di appartenenza e le date di inizio e fine del monitoraggio. Le città sono collegate alle stazioni di rilevamento ed ai veicoli tramite la proprietà `hasCity`.\n",
    "\n",
    "`MeasureUnit` definisce le unità di misura utilizzate nelle rilevazioni, caratterizzate da descrizioni e simboli specifici. Queste unità sono collegate agli inquinanti e alle temperature tramite la proprietà `hasMeasureUnit`.\n",
    "\n",
    "La classe `Measurement` contiene i dati delle misurazioni effettuate, specificando la data, l'intervallo di misura e il valore rilevato. Le misurazioni sono associate agli inquinanti e alle stazioni di rilevamento tramite le proprietà `hasPolluting` e `hasStation`.\n",
    "\n",
    "`Polluting` rappresenta le sostanze inquinanti monitorate, descritte attraverso simboli e descrizioni. Gli inquinanti hanno una temperatura associata tramite la proprietà `hasTemperature`.\n",
    "\n",
    "`Station` descrive le stazioni di rilevamento, con informazioni sulle coordinate geografiche, l'altitudine e la tipologia della stazione. Le stazioni sono connesse alle città tramite la proprietà `hasCity`.\n",
    "\n",
    "La classe `Temperature` rappresenta le misurazioni di temperatura, con descrizioni e valori standard di riferimento. Queste misurazioni sono parte integrante delle rilevazioni di inquinanti.\n",
    "\n",
    "Infine, la classe `Vehicle` include i veicoli utilizzati per il monitoraggio, con dettagli come marca, categoria, data di rilevazione, cilindrata, classe EURO, tipo di carburante, potenza, tipologia e utilizzo. I veicoli sono collegati alle città tramite la proprietà `hasCity`.\n",
    "\n",
    "L'ontologia descritta è stata serializzata nel formato `ttl` ed è stata riportata nel file: `ontology.ttl`. <br>\n",
    "L'URI dell'ontologia è `http://www.enviromentalpolluting.it/ontology`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`4.2 Passaggio a 5 stelle`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per il passaggio dei dataset da 3 a 5 stelle ci si è basati sullo standard RDF di W3C, congiunto con la libreria `rdflib` di Python.\n",
    "\n",
    "Il primo step è stata l'inizializzazione del grafo RDF e dei namespace di interesse.  \n",
    "Per identificare le risorse, a partire dall'URI di base `http://www.enviromentalpolluting.it/resource/`, si sono fatte le seguenti scelte:\n",
    "\n",
    "- Per le `città` sono stati utilizzati come identificativi i codici ISTAT.\n",
    "- Per le `stazioni della qualità dell'aria`, `stazioni della temperatura` e gli `inquinanti` sono stati utilizzati i relativi ID.\n",
    "- Per le `unità di misura` sono stati utilizzati gli ID rappresentati dal simbolo corrispondente all'unità di misura.\n",
    "- Per la `temperatura` è stato utilizzato il valore standard e il simbolo dell'unità di misura.\n",
    "- Per i `veicoli` è stato utilizzato un contatore, vista la mancanza di un attributo univoco per identificare gli stessi.\n",
    "- Per le `misurazioni` sono stati utilizzati gli ID delle stazioni concatenati con l'ID dell'inquinante rilevato e con la data in cui è avvenuta la misurazione.\n",
    "\n",
    "Per quanto riguarda l'interlinking viene sfruttato il vocabolario controllato dei comuni d'italia `https://w3id.org/italia/controlled-vocabulary/territorial-classifications/cities/` realizzanado un collegamento con le città della nostra base di conoscenza attraverso la proprietà `owl:sameAs` e il relativo codice istat che viene utilizzato per completare la URI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDF Creazione e settaggio di tutti i namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafoDelleConoscenze = Graph()\n",
    "ONTO = Namespace(\"http://www.enviromentalpollution.it/ontology/\")\n",
    "CITY = Namespace(\"http://www.enviromentalpollution.it/resource/cities/\")\n",
    "STATION_AIR = Namespace(\"http://www.enviromentalpollution.it/resource/stationsAir/\")\n",
    "STATION_TEMP = Namespace(\"http://www.enviromentalpollution.it/resource/stationsTemp/\")\n",
    "POLLUTING = Namespace(\"http://www.enviromentalpollution.it/resource/pollutings/\")\n",
    "MEASUREMENT_AIR = Namespace(\"http://www.enviromentalpollution.it/resource/measurementsAir/\")\n",
    "MEASUREMENT_TEMP= Namespace(\"http://www.enviromentalpollution.it/resource/measurementsTemp/\")\n",
    "TEMPERATURE = Namespace(\"http://www.enviromentalpollution.it/resource/temperatures/\")\n",
    "MEASURE_UNIT = Namespace(\"http://www.enviromentalpollution.it/resource/measureUnits/\")\n",
    "VEHICLE = Namespace(\"http://www.enviromentalpollution.it/resource/vehicles/\")\n",
    "\n",
    "grafoDelleConoscenze.bind(\"onto\",ONTO)\n",
    "grafoDelleConoscenze.bind(\"city\",CITY)\n",
    "grafoDelleConoscenze.bind(\"stationAir\",STATION_AIR)\n",
    "grafoDelleConoscenze.bind(\"stationTemp\",STATION_TEMP)\n",
    "grafoDelleConoscenze.bind(\"polluting\",POLLUTING)\n",
    "grafoDelleConoscenze.bind(\"measurementAir\",MEASUREMENT_AIR)\n",
    "grafoDelleConoscenze.bind(\"measurementTemp\",MEASUREMENT_TEMP)\n",
    "grafoDelleConoscenze.bind(\"temperature\",TEMPERATURE)\n",
    "grafoDelleConoscenze.bind(\"measureUnit\",MEASURE_UNIT)\n",
    "grafoDelleConoscenze.bind(\"vehicle\",VEHICLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento delle città nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiCittaGrafo(rowCitta):\n",
    "    catalogoCitta = \"https://w3id.org/italia/controlled-vocabulary/territorial-classifications/cities/\"\n",
    "    urlCitta = URIRef(CITY+rowCitta[2])\n",
    "    interlinkingCitta = URIRef(catalogoCitta+rowCitta[2]+\"-(\"+rowCitta[3].strftime(\"%Y-%m-%d\")+\")\")\n",
    "    grafoDelleConoscenze.add([urlCitta, RDF.type, ONTO.City])\n",
    "    grafoDelleConoscenze.add([urlCitta,RDFS.label,Literal(rowCitta[0],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlCitta,ONTO.hasIstatCode,Literal(rowCitta[2],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlCitta,ONTO.hasProvince,Literal(rowCitta[1],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlCitta,ONTO.hasStartDate,Literal(rowCitta[3],datatype=XSD.date)])\n",
    "    grafoDelleConoscenze.add([urlCitta,ONTO.hasEndDate,Literal(rowCitta[4],datatype=XSD.date)])\n",
    "    grafoDelleConoscenze.add([urlCitta,OWL.sameAs,interlinkingCitta])\n",
    "    \n",
    "\n",
    "rowsCitta = database.execute(\"SELECT * FROM parquet_scan('parquet/citta_province_codiceIstat.parquet')\").fetchall()\n",
    "for rowCitta in rowsCitta:\n",
    "    aggiungiCittaGrafo(rowCitta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento delle stazioni dell'aria nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiStazioneAriaGrafo(rowStazione):\n",
    "    urlStazione = URIRef(STATION_AIR+str(rowStazione[0]))\n",
    "    codiceIstat = database.execute(f\"SELECT codiceIstat FROM parquet_scan('parquet/citta_province_codiceIstat.parquet') WHERE lower(nomeCitta)='{rowStazione[1].lower()}'\").fetchall()[0][0]\n",
    "    urlCitta = URIRef(CITY+str(codiceIstat))\n",
    "    grafoDelleConoscenze.add([urlStazione, RDF.type, ONTO.Station])\n",
    "    grafoDelleConoscenze.add([urlStazione,ONTO.hasId,Literal(rowStazione[0],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlStazione,ONTO.hasTipology,Literal(\"Aria\",datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlStazione,RDFS.label,Literal(rowStazione[2],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlStazione,ONTO.hasCity,urlCitta])\n",
    "    grafoDelleConoscenze.add([urlStazione,ONTO.hasLatitudine,Literal(rowStazione[3],datatype=XSD.float)])\n",
    "    grafoDelleConoscenze.add([urlStazione,ONTO.hasLogitudine,Literal(rowStazione[4],datatype=XSD.float)])\n",
    "\n",
    "rowsStazioni = database.execute(\"SELECT * FROM parquet_scan('parquet/arpa_qualita_aria_anagrafica_stazioni.parquet')\").fetchall()\n",
    "for rowStazione in rowsStazioni:\n",
    "    aggiungiStazioneAriaGrafo(rowStazione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento delle stazioni della temperatura nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiStazioneRDF(rowStazione):\n",
    "    urlStation = URIRef(STATION_TEMP+str(rowStazione[0]))\n",
    "    grafoDelleConoscenze.add([urlStation,RDF.type,ONTO.Station])\n",
    "    grafoDelleConoscenze.add([urlStation,RDFS.label,Literal(rowStazione[1],datatype=XSD.string)])\n",
    "    istatCode = database.execute(f\"SELECT codiceIstat FROM parquet_scan('parquet/citta_province_codiceIstat.parquet') WHERE codiceIstat = '{rowStazione[5]}'\").fetchall()\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasCity,URIRef(CITY+istatCode[0][0])])\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasTipology,Literal(\"Temperatura\",datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasId,Literal(rowStazione[0],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasAltitude,Literal(rowStazione[2],datatype=XSD.int)])\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasLongitude,Literal(rowStazione[3],datatype=XSD.float)])\n",
    "    grafoDelleConoscenze.add([urlStation,ONTO.hasLatitude,Literal(rowStazione[4],datatype=XSD.float)])\n",
    "    \n",
    "\n",
    "rowsStazione = database.execute(\"SELECT * FROM parquet_scan('parquet/elenco_sensori_meteo.parquet')\").fetchall()\n",
    "for rowStazione in rowsStazione:\n",
    "    aggiungiStazioneRDF(rowStazione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento degli inquinanti nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiInquinanteGrafo(rowInquinante):\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Temp,RDF.type,ONTO.MeasureUnit])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Temp,ONTO.hasSymbol,Literal(rowInquinante[7],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Temp,ONTO.hasId,Literal(\"k\",datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Temp,ONTO.hasDescription,Literal(\"kelvin\",datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlTemperature,RDF.type,ONTO.Temperature])\n",
    "    grafoDelleConoscenze.add([urlTemperature,ONTO.hasMeasureUnit,urlMeasureUnit_Temp])\n",
    "    grafoDelleConoscenze.add([urlTemperature,ONTO.hasStandardValue,Literal(rowInquinante[6],datatype=XSD.unsignedInt)])\n",
    "    grafoDelleConoscenze.add([urlTemperature,ONTO.hasDescription,Literal(rowInquinante[8],datatype=XSD.string)])\n",
    "\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Poll,RDF.type,ONTO.MeasureUnit])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Poll,ONTO.hasSymbol,Literal(rowInquinante[3],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Poll,ONTO.hasId,Literal(rowInquinante[4],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlMeasureUnit_Poll,ONTO.hasDescription,Literal(rowInquinante[5],datatype=XSD.string)])\n",
    "\n",
    "    urlInquinante = URIRef(POLLUTING+str(rowInquinante[0]))\n",
    "    grafoDelleConoscenze.add([urlInquinante,RDF.type,ONTO.Polluting])\n",
    "    grafoDelleConoscenze.add([urlInquinante,ONTO.hasId,Literal(rowInquinante[0],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlInquinante,ONTO.hasSymbol,Literal(rowInquinante[1],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlInquinante,ONTO.hasDescription,Literal(rowInquinante[2],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlInquinante,ONTO.hasTemperature,urlTemperature])\n",
    "    grafoDelleConoscenze.add([urlInquinante,ONTO.hasMeasureUnit,urlMeasureUnit_Poll])\n",
    "\n",
    "\n",
    "urlTemperature = URIRef(TEMPERATURE+\"293-k\")\n",
    "urlMeasureUnit_Temp = URIRef(MEASURE_UNIT+\"k\")\n",
    "\n",
    "urlMeasureUnit_Poll = URIRef(MEASURE_UNIT+\"ug.m-3\")\n",
    "\n",
    "rowsInquinante = database.execute(\"SELECT * FROM parquet_scan('parquet/arpa_qualita_aria_anagrafica_inquinanti.parquet')\").fetchall()\n",
    "for rowInquinante in rowsInquinante:\n",
    "    aggiungiInquinanteGrafo(rowInquinante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento dei veicoli nel grafo.  \n",
    "\n",
    "_Vista la dimensione del parco circolante e gli enormi costi di esecuzione, si è deciso di limitare l'inserimento a 200.000 veicoli così da limitare il costo d'esecuzione_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiVeicoloGrafo(rowVeicolo,serialNumber):\n",
    "    urlVeicolo = URIRef(VEHICLE + str(serialNumber))\n",
    "    grafoDelleConoscenze.add([urlVeicolo,RDF.type,ONTO.Vehicle])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasId,Literal(serialNumber,datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasTypology,Literal(rowVeicolo[0],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasCategory,Literal(rowVeicolo[1],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasUsage,Literal(rowVeicolo[2],datatype=XSD.string)])\n",
    "    istatCode = database.execute(f\"SELECT codiceIstat FROM parquet_scan('parquet/citta_province_codiceIstat.parquet') WHERE lower(nomeCitta) = lower('{rowVeicolo[3]}')\").fetchall()\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasCity,URIRef(CITY+istatCode[0][0])])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasBrand,Literal(rowVeicolo[4],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasDisplacement,Literal(rowVeicolo[5],datatype=XSD.float)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasFuel,Literal(rowVeicolo[6],datatype=XSD.string)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasHorsepower,Literal(rowVeicolo[7],datatype=XSD.unsignedInt)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasDate,Literal(rowVeicolo[8],datatype=XSD.date)])\n",
    "    grafoDelleConoscenze.add([urlVeicolo,ONTO.hasEURO,Literal(rowVeicolo[9],datatype=XSD.unsignedInt)])\n",
    "\n",
    "serialNumber = 1\n",
    "rowsVeicolo = database.execute(\"SELECT * FROM parquet_scan('parquet/Circolante_Sicilia.parquet') LIMIT 200000\").fetchall()\n",
    "for rowVeicolo in rowsVeicolo:\n",
    "    aggiungiVeicoloGrafo(rowVeicolo,serialNumber)\n",
    "    serialNumber+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento misurazioni stazioni dell'aria nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiMisurazioneAriaGrafo(rowMisurazione):\n",
    "    urlMisurazione = URIRef(MEASUREMENT_AIR+str(rowMisurazione[0])+\"-\"+str(rowMisurazione[1])+\"-(\"+rowMisurazione[3].strftime(\"%Y-%m-%d\")+\")\")\n",
    "    urlStazione = URIRef(STATION_AIR+str(rowMisurazione[0]))\n",
    "    urlInquinante = URIRef(POLLUTING+str(rowMisurazione[1]))\n",
    "    grafoDelleConoscenze.add([urlMisurazione, RDF.type, ONTO.Measurement])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasStation,urlStazione])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasPolluting,urlInquinante])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasValue,Literal(rowMisurazione[2],datatype=XSD.float)])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasDate,Literal(rowMisurazione[3],datatype=XSD.date)])\n",
    "\n",
    "def aggiungiMisurazioniAriaGrafo(path):\n",
    "    rowsMisurazioni = database.execute(f\"SELECT * FROM parquet_scan('{path}')\").fetchall()\n",
    "    for rowMisurazione in rowsMisurazioni:\n",
    "        aggiungiMisurazioneAriaGrafo(rowMisurazione)\n",
    "\n",
    "percorsi = [\n",
    "    \"parquet/arpa_qualita_aria_2020_1.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_5.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_8.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_10.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_20.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_32.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_38.parquet\",\n",
    "    \"parquet/arpa_qualita_aria_2020_6001.parquet\"\n",
    "]\n",
    "for path in percorsi:\n",
    "    aggiungiMisurazioniAriaGrafo(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimento misurazioni stazioni della temperatura nel grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggiungiMisurazioneTemperaturaGrafo(rowMisurazione):\n",
    "    urlMisurazione = URIRef(MEASUREMENT_TEMP+str(rowMisurazione[0])+\"-(\"+rowMisurazione[2].strftime(\"%Y-%m-%d\")+\")\")\n",
    "    urlStazione = URIRef(STATION_TEMP+str(rowMisurazione[0]))\n",
    "    grafoDelleConoscenze.add([urlMisurazione, RDF.type, ONTO.Measurement])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasStation,urlStazione])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasValue,Literal(rowMisurazione[1],datatype=XSD.float)])\n",
    "    grafoDelleConoscenze.add([urlMisurazione,ONTO.hasDate,Literal(rowMisurazione[2],datatype=XSD.date)])\n",
    "\n",
    "def aggiungiMisurazioniTemperaturaGrafo(path):\n",
    "    rowsMisurazioni = database.execute(f\"SELECT * FROM parquet_scan('{path}')\").fetchall()\n",
    "    for rowMisurazione in rowsMisurazioni:\n",
    "        aggiungiMisurazioneTemperaturaGrafo(rowMisurazione)\n",
    "\n",
    "percorsi = [\n",
    "    \"parquet/sias_temperatura_aria_a_2_metri_2020_4.parquet\",\n",
    "    \"parquet/sias_temperatura_aria_a_2_metri_2020_7.parquet\",\n",
    "    \"parquet/sias_temperatura_aria_a_2_metri_2020_10.parquet\",\n",
    "    \"parquet/sias_temperatura_aria_a_2_metri_2020_12.parquet\"\n",
    "]\n",
    "for path in percorsi:\n",
    "    aggiungiMisurazioniTemperaturaGrafo(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estrazione del grafo in turtle (RDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafoDelleConoscenze.serialize(destination='inquinamento.ttl', format='turtle', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __`5 Data visualization`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo aver elevato i nostri dati a 5 stelle, è stato possibile estrarre alcune informazioni rilevanti attraverso l'uso di query SQL con DuckDB sui file Parquet e strumenti di visualizzazione come `Datawrapper` e `Fluorish`.  \n",
    "La scelta di non utilizzare query SPARQL sul grafo di conoscenza è dovuta alla dimensione del parco circolante per cui la creazione del RDF richiederebbe troppo tempo.  \n",
    "Inoltre seppur si volessero eseguire query SPARQL, sempre per questioni di costo d'esecuzione si dovrebbero eseguire query su un grafo con un numero di veicoli limitati andando così a falsare i risultati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione della tabella contenente i risultati da utilizzare per la data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.execute(\"\"\"\n",
    "                 CREATE OR REPLACE TABLE 'dataVisualization'(\n",
    "                    citta VARCHAR(100) PRIMARY KEY,\n",
    "                    EURO0 INTEGER DEFAULT 0,\n",
    "                    EURO1 INTEGER DEFAULT 0,\n",
    "                    EURO2 INTEGER DEFAULT 0,\n",
    "                    EURO3 INTEGER DEFAULT 0,\n",
    "                    EURO4 INTEGER DEFAULT 0,\n",
    "                    EURO5 INTEGER DEFAULT 0,\n",
    "                    EURO6 INTEGER DEFAULT 0,\n",
    "                    inquinante1 DOUBLE DEFAULT 0,\n",
    "                    inquinante5 DOUBLE DEFAULT 0,\n",
    "                    inquinante8 DOUBLE DEFAULT 0,\n",
    "                    inquinante10 DOUBLE DEFAULT 0,\n",
    "                    inquinante20 DOUBLE DEFAULT 0,\n",
    "                    inquinante32 DOUBLE DEFAULT 0,\n",
    "                    inquinante38 DOUBLE DEFAULT 0,\n",
    "                    inquinante6001 DOUBLE DEFAULT 0,\n",
    "                    temperatura DOUBLE DEFAULT 0\n",
    "                                        \n",
    "                )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`EURO per città`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conteggio dei veicoli per città in base all'EURO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.execute(\"\"\"\n",
    "                 CREATE OR REPLACE VIEW 'conteggioVeicoli' AS\n",
    "                 SELECT Città AS citta, EURO AS EURO, COUNT(EURO) as numeroVeicoli\n",
    "                 FROM parquet_scan('parquet/Circolante_Sicilia.parquet')\n",
    "                 GROUP BY (Città, EURO)\n",
    "                 ORDER BY (Città, EURO)\n",
    "                 \"\"\").fetchall()\n",
    "database.execute(\"INSERT INTO 'dataVisualization' (citta) SELECT DISTINCT(citta) FROM conteggioVeicoli\")\n",
    "rowsVeicoli = database.execute(\"SELECT * FROM 'conteggioVeicoli'\").fetchall()\n",
    "for rowVeicolo in rowsVeicoli:\n",
    "    database.execute(f\"UPDATE 'dataVisualization' SET {\"EURO\"+str(rowVeicolo[1])}={rowVeicolo[2]} WHERE citta='{rowVeicolo[0]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/EURO/EUROzero.png\" alt=\"EURO 0\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROuno.png\" alt=\"EURO 1\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROdue.png\" alt=\"EURO 2\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROtre.png\" alt=\"EURO 3\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROquattro.png\" alt=\"EURO 4\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROcinque.png\" alt=\"EURO 5\" style=\"width: 85%;\"/>\n",
    "    <img src=\"./dataVisualization/EURO/EUROsei.png\" alt=\"EURO 6\" style=\"width: 85%;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ci si poteva aspettare la maggiorparte dei veicoli con `EURO` basso è situata nelle città di `Catania` e `Palermo`, che sono anche le città più popolose e quindi con un maggior numero di veicoli in generale.  \n",
    "Da ciò che emerge da questi grafici ci si aspetta che la __temperatura media__ così come il __valore medio degli inquinanti__ sia maggiore proprio nelle città che presentano molti veicoli dal valore `EURO` basso.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`Media Temperatura e Inquinanti`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo valore medio per inquinante e per temperatura, associato a ciascuna città, per i mesi di aprile, luglio, ottobre e dicembre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misurazioneAriaInquinante(path,inquinante,mese):\n",
    "    rowsMisurazioni = database.execute(f\"\"\"\n",
    "                                        SELECT upper(file2.citta) AS citta, AVG(file1.valoreMisurato) AS valoreMisurato\n",
    "                                        FROM parquet_scan('{path}') AS file1\n",
    "                                        INNER JOIN parquet_scan('parquet/arpa_qualita_aria_anagrafica_stazioni.parquet') AS file2\n",
    "                                        ON file1.stazioneId = file2.stazione_id\n",
    "                                        WHERE upper(file2.citta) IN (SELECT upper(citta) FROM 'dataVisualization') AND EXTRACT(MONTH FROM file1.data)={mese}\n",
    "                                        GROUP BY (file2.citta)\n",
    "                                        ORDER BY (file2.citta)\n",
    "                                \"\"\").fetchall()\n",
    "    for rowMisurazione in rowsMisurazioni:\n",
    "        database.execute(f\"UPDATE 'dataVisualization' SET {\"inquinante\"+str(inquinante)}={rowMisurazione[1]} WHERE citta='{rowMisurazione[0]}'\")\n",
    "def creazioneMeseCsvDataVisualization(mese):\n",
    "    percorsi = [\n",
    "        \"parquet/arpa_qualita_aria_2020_1.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_5.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_8.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_10.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_20.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_32.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_38.parquet\",\n",
    "        \"parquet/arpa_qualita_aria_2020_6001.parquet\"\n",
    "    ]\n",
    "    inquinanti = [\n",
    "        1,\n",
    "        5,\n",
    "        8,\n",
    "        10,\n",
    "        20,\n",
    "        32,\n",
    "        38,\n",
    "        6001\n",
    "    ]\n",
    "    for i in range(0, len(percorsi)-1):\n",
    "        misurazioneAriaInquinante(percorsi[i],inquinanti[i],mese)\n",
    "    rowsMisurazioni = database.execute(f\"\"\"\n",
    "                                        SELECT upper(file2.COMUNE_NOME) as citta, AVG(valoreMisurato) as valoreMisurato\n",
    "                                        FROM parquet_scan('{\"parquet/sias_temperatura_aria_a_2_metri_2020_\"+str(mese)+\".parquet\"}') AS file1\n",
    "                                        INNER JOIN parquet_scan('parquet/elenco_sensori_meteo.parquet') AS file2\n",
    "                                        ON file1.stazioneId = file2.ID_STAZ\n",
    "                                        WHERE upper(file2.COMUNE_NOME) IN (SELECT upper(citta) FROM 'dataVisualization')\n",
    "                                        GROUP BY (file2.COMUNE_NOME)\n",
    "                                        ORDER BY (file2.COMUNE_NOME)\n",
    "                                \"\"\").fetchall()\n",
    "    for rowMisurazione in rowsMisurazioni:\n",
    "        database.execute(f\"UPDATE 'dataVisualization' SET temperatura={rowMisurazione[1]} WHERE citta='{rowMisurazione[0]}'\")\n",
    "    database.execute(f\"\"\"\n",
    "                        COPY (\n",
    "                            SELECT * FROM dataVisualization\n",
    "                        )\n",
    "                         TO '{\"csv/dataVisualization_mese_\"+str(mese)+\".csv\"}' (FORMAT CSV, HEADER);\n",
    "                            \n",
    "                \"\"\")\n",
    "\n",
    "mesi = [\n",
    "    4,\n",
    "    7,\n",
    "    10,\n",
    "    12\n",
    "]\n",
    "for mese in mesi:\n",
    "    creazioneMeseCsvDataVisualization(mese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`Temperatura media`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/temperatura/TemperaturaAprile.png\" alt=\"Temperatura Aprile\" style=\"width: 85%; height: 90%\"/>\n",
    "    <img src=\"./dataVisualization/temperatura/TemperaturaLuglio.png\" alt=\"Temperatura Luglio\" style=\"width: 85%; height: 90%\"/>\n",
    "    <img src=\"./dataVisualization/temperatura/TemperaturaOttobre.png\" alt=\"Temperatura Ottobre\" style=\"width: 85%; height: 90%\"/>\n",
    "    <img src=\"./dataVisualization/temperatura/TemperaturaDicembre.png\" alt=\"Temperatura Dicembre\" style=\"width: 85%; height: 90%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può osservare dai grafici, a parte che nel mese di Luglio in cui la temperatura media è pressoché equivalente in tutte le città, nei mesi di Aprile, Ottobre e Dicembre si nota bene che i picchi di temperaura seppur di pochi gradi li si hanno nelle città di `Palermo` e `Catania`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`Inquinanti medi`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Vista la mancanza delle misurazioni di alcuni inquinanti per diverse città rispetto ai mesi presi in considerazione, si è deciso di visulizzare esclusivamente i risultati relativi a quegli inquinanti per cui erano presenti più valori per la maggiorparte delle città prese in considerazione nella nostra indagine. Ovvero gli ossidi di azoto (`NO`, `NO2`), il biossido di zolfo (`SO2`) e il particolato fine (`PM10`)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`Aprile`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/inquinanti/NO2Aprile.png\" alt=\"NO2 Aprile\" style=\"width: 85%; height: 90%\"/>\n",
    "    <img src=\"./dataVisualization/inquinanti/PM10Aprile.png\" alt=\"PM10 Aprile\" style=\"width: 85%; height: 90%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`Luglio`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/inquinanti/NO-NO2Luglio.png\" alt=\"NO-NO2 Luglio\" style=\"width: 85%; height: 100%\"/>\n",
    "    <img src=\"./dataVisualization/inquinanti/PM10Luglio.png\" alt=\"PM10 Luglio\" style=\"width: 85%; height: 90%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`Ottobre`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/inquinanti/inquinantiOttobre.png\" alt=\"inquinanti Ottobre\" style=\"width: 100%; height: 100%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __`Dicembre`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px;\">\n",
    "    <img src=\"./dataVisualization/inquinanti/inquinantiDicembre.png\" alt=\"inquinanti Dicembre\" style=\"width: 100%; height: 100%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche in questo caso si può notare come le città con il valore medio di inquinanti registrato sono `Catania` e `Palermo` soprattutto per quanto riguarda gli ossidi di azoto e il particolato fine, anche se nel mese di Dicembre si registrano valori piuttosto elevati anche per la città di `Siracusa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>In conclusione la nostra indagine, anche se in scala ridotta vista l'analisi incentrata su un solo anno e la mancanza di alcune misurazioni, ha prodotto i risultati che ci si aspettava, confermando che l'utilizzo di veicoli con un EURO basso, e quindi che producono maggiore inquinamento, contribuisce ad una temperatura media più alta e una maggiore concentrazione di agenti inquinanti per le città in cui circolano.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiusura connessione con duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`Query SPARQL`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Vista la dimensione del grafo, l'esecuzione di query SPARQL richiederebbe troppo tempo con la libreria rdflib. Pertanto, le query in seguito, equivalenti a quelle SQL per ottenere le informazioni per la data visualization, sono state eseguite e verificate con lo strumento GraphDB._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query SPARQL per il conteggio dei veicoli per città in base alla categoria di emissione (EURO). Costo di esecuzione su graphdb: 0.4s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sparql\n",
    "SELECT ?nomeCitta ?EURO (COUNT(*) AS ?numeroVeicoli) \n",
    "    WHERE {\n",
    "        ?veicolo a onto:Vehicle . \n",
    "        ?veicolo onto:hasEURO ?EURO .\n",
    "        ?veicolo onto:hasCity ?citta .\n",
    "        ?citta rdfs:label ?nomeCitta\n",
    "    }\n",
    "    GROUP BY ?nomeCitta ?EURO\n",
    "    ORDER BY ?nomeCitta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo valore medio per inquinante, associato a ciascuna città, per il mese di Aprile. Costo di esecuzione su graphdb: 0.1s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sparql\n",
    "SELECT ?nomeCitta (AVG(?valoreMisurato) AS ?valore)\n",
    "    WHERE {\n",
    "        ?misurazione a onto:Measurement .\n",
    "        ?misurazione onto:hasPolluting polluting:1 .\n",
    "        ?misurazione onto:hasValue ?valoreMisurato .\n",
    "        ?misurazione onto:hasDate ?data .\n",
    "        ?misurazione onto:hasStation ?stazione .\n",
    "        ?stazione onto:hasCity ?citta .\n",
    "        ?citta rdfs:label ?nomeCitta .\n",
    "        ?veicolo a onto:Vehicle .\n",
    "        ?veicolo onto:hasCity ?citta .\n",
    "        FILTER (MONTH(?data) = 4)\n",
    "    }\n",
    "    GROUP BY ?nomeCitta\n",
    "\tORDER BY ?nomeCitta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo valore medio per temperatura, associato a ciascuna città, per il mese di Aprile. Costo di esecuzione su graphdb: 0.12s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sparql\n",
    "SELECT ?nomeCitta (AVG(?valoreMisurato) AS ?valore)\n",
    "    WHERE {\n",
    "        ?misurazione a onto:Measurement .\n",
    "        ?misurazione onto:hasValue ?valoreMisurato .\n",
    "        ?misurazione onto:hasDate ?data .\n",
    "        ?misurazione onto:hasStation ?stazione .\n",
    "    \t?stazione onto:hasTipology \"Temperatura\" .\n",
    "        ?stazione onto:hasCity ?citta .\n",
    "        ?citta rdfs:label ?nomeCitta .\n",
    "    \t?veicolo a onto:Vehicle .\n",
    "        ?veicolo onto:hasCity ?citta .\n",
    "    \tFILTER(MONTH(?data)=4)\n",
    "    }\n",
    "\tGROUP BY ?nomeCitta\n",
    "\tORDER BY ?nomeCitta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le query vengono eseguite in egual modo, cambiando solo `id inquinante` e `numero mese`, per i mesi di Luglio, Ottobre e Dicembre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`Creazione mappa google maps delle stazioni`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sparql\n",
    "SELECT ?nomeStazione ?longitudine ?latitudine\n",
    "    WHERE {\n",
    "    \t?stazione a onto:Station .\n",
    "    \t?stazione rdfs:label ?stationName .\n",
    "    \t?stazione onto:hasLatitudine ?latitudine .\n",
    "    \t?stazione onto:hasLogitudine ?longitudine .\n",
    "    \t?stazione onto:hasCity ?citta .\n",
    "    \t?citta rdfs:label ?nomeCitta\n",
    "    \tBIND(CONCAT(?stationName, \" - \", ?nomeCitta) AS ?nomeStazione)\n",
    "    }\n",
    "\tORDER BY ?nomeStazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://www.google.com/maps/d/embed?mid=1oWWR3KbcTQVg1JzVptKyuxSuUEIrCZM&ehbc=2E312F\" width=\"820\" height=\"580\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
